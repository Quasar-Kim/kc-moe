include 'flaxformer/t5x/configs/moe/models/st_moe_base.gin'
include 'config/run/1_moe/finetune_default.gin'

# 2^17 tokens in one step
# dataset has approx.100,000 tokens
# -> 1 step = one epoch
# train for 128 epochs -> 128 steps
TASK_FEATURE_LENGTHS = {"inputs": 512, "targets": 32}
TRAIN_STEPS = 131_200 # 128 + 131072
MIXTURE_OR_TASK_NAME = 'question_pair'
INITIAL_CHECKPOINT_PATH = 'gs://kc-moe-eu/t5x/pretrain/1-kc-moe-base/checkpoint_131072'
MODEL_DIR = 'gs://kc-moe-eu/t5x/question-pair/1-kc-moe-base'
EVAL_PERIOD = 1
CHECKPOINT_PERIOD = 4