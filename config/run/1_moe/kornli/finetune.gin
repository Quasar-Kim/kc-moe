include 'flaxformer/t5x/configs/moe/models/st_moe_base.gin'
include 'config/run/1_moe/finetune_default.gin'

# 2^17(2^9 * 2^8) tokens per step
# dataset has approx. 30,000,000 tokens
# -> 300 steps = one epoch
# train for 20 epochs -> 6000 steps
TASK_FEATURE_LENGTHS = {"inputs": 512, "targets": 32}
TRAIN_STEPS = 137_072 # 6000 + 131072
MIXTURE_OR_TASK_NAME = 'kornli'
INITIAL_CHECKPOINT_PATH = 'gs://kc-moe-eu/t5x/pretrain/1-kc-moe-base/checkpoint_131072'
MODEL_DIR = 'gs://kc-moe-eu/t5x/kornli/1-kc-moe-base'
EVAL_PERIOD = 100
CHECKPOINT_PERIOD = 400