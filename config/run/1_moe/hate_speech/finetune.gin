include 'flaxformer/t5x/configs/moe/models/st_moe_base.gin'
include 'config/run/1_moe/finetune_default.gin'

# 2^17(2^9 * 2^8) tokens per step
# dataset has approx. 150,000 tokens
# -> 2 steps = one epoch
# train for 128 epochs -> 256 steps
TASK_FEATURE_LENGTHS = {"inputs": 512, "targets": 32}
TRAIN_STEPS = 131_328 # 256 + 131_328
MIXTURE_OR_TASK_NAME = 'hate_speech'
INITIAL_CHECKPOINT_PATH = 'gs://kc-moe-eu/t5x/pretrain/1-kc-moe-base/checkpoint_131072'
MODEL_DIR = 'gs://kc-moe-eu/t5x/hate-speech/1-kc-moe-base'
EVAL_PERIOD = 1
CHECKPOINT_PERIOD = 4